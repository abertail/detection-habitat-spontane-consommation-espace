{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f2497f-1bd7-4ac5-b5ef-7d6dec615a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba9c5b2-6a7f-4469-9595-d628b1aa4ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tifffile\n",
    "!pip install tqdm # progresbar\n",
    "!pip3 install torch torchvision torchaudio -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5625e52d-cab1-426b-a00d-6ab849fd14d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import s3fs\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "from tifffile import TiffFile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader,  random_split\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0ea7dc-8956-4f8b-ad90-633dece62c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available() : device= torch.device(\"cuda:0\" )\n",
    "else : device = \"cpu\"\n",
    "\n",
    "print(\"Using {} device\".format(device))\n",
    "if torch.cuda.is_available() :\n",
    "    print(\"nom du GPU :\", torch.cuda.get_device_name(device=None))\n",
    "    print(\"GPU initialisé : \", torch.cuda.is_initialized())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aea902-5aba-4234-9e83-c69b768d8497",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': 'https://minio.lab.sspcloud.fr'})\n",
    "fs.get('projet-funathon/2022/Sujet9_deep_learning_donnees_satellites/additional_files_earthcube_emu4zqr.zip', 'additional_files_earthcube_emu4zqr.zip')\n",
    "shutil.unpack_archive('additional_files_earthcube_emu4zqr.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9805dbeb-1aee-4b22-b6d2-f3b208bf9b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER_STR = 'dataset'\n",
    "DATA_FOLDER = Path(DATA_FOLDER_STR).expanduser()\n",
    "DATASET_FOLDER = DATA_FOLDER\n",
    "\n",
    "# get all train images and masks\n",
    "train_images_paths = sorted(list(DATASET_FOLDER.glob('train/images/*.tif')))\n",
    "train_masks_paths = sorted(list(DATASET_FOLDER.glob('train/masks/*.tif')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e8295-d912-4321-aa59-0b9503012fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths,mask_paths):   # initial logic happens like transform\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        with TiffFile(self.mask_paths[idx]) as tif :\n",
    "            mask = tif.asarray()\n",
    "        \n",
    "        with TiffFile(self.image_paths[idx]) as tif :\n",
    "            image = np.array(tif.asarray())\n",
    "     \n",
    "        t_mask = torch.tensor(mask,dtype = torch.long)\n",
    "        image = torch.tensor(np.array(image,dtype = float), dtype =torch.float)\n",
    "        \n",
    "        ID = str(self.mask_paths[idx])\n",
    "     \n",
    "        return {\"image\": image, \"masque\" : t_mask, \"id\" : ID} \n",
    "        \n",
    "        \n",
    "    def __len__(self):  \n",
    "        return len(self.mask_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6129c158-31b7-400f-82c7-b174464b7126",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandCoverData():\n",
    "   \n",
    "    IMG_SIZE = 256\n",
    "    N_CHANNELS = 4\n",
    "    N_CLASSES = 10\n",
    "    MEAN_CHANNEL = [ 339.42029674, 570.98497474,  539.11161384, 2634.49868179] \n",
    "    STD_CHANNEL = [ 339.79895785, 404.86935149,  549.41877854, 1071.38939764]\n",
    "    COUNT_CLASS =  np.array([0, 20643, 60971025, 404760981, 277012377, 96473046, 333407133, 9775295, 1071, 29404605])\n",
    "    WEIGHT_CLASS = np.array([0.0000e+00, 0.0000e+00, 1.6401e-08, 2.4706e-09, 3.6099e-09, 1.0366e-08,\n",
    "        2.9993e-09, 1.0230e-07, 9.3371e-04, 3.4008e-08])*np.sum(COUNT_CLASS)\n",
    "    CLASSES = [\n",
    "    'no_data',\n",
    "    'clouds',\n",
    "    'artificial',\n",
    "    'cultivated',\n",
    "    'broadleaf',\n",
    "    'coniferous',\n",
    "    'herbaceous',\n",
    "    'natural',\n",
    "    'snow',\n",
    "    'water']\n",
    "    \n",
    "    TRAINSET_SIZE = 18491\n",
    "    TESTSET_SIZE = 5043\n",
    "    \n",
    "    CLASSES_COLORPALETTE = {\n",
    "    0: [0,0,0],\n",
    "    1: [255,25,236],\n",
    "    2: [215,25,28],\n",
    "    3: [211,154,92],\n",
    "    4: [33,115,55],\n",
    "    5: [21,75,35],\n",
    "    6: [118,209,93],\n",
    "    7: [130,130,130],\n",
    "    8: [255,255,255],\n",
    "    9: [43,61,255]\n",
    "    }\n",
    "    CLASSES_COLORPALETTE = {c: np.asarray(color) for (c, color) in CLASSES_COLORPALETTE.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c0df7b-a285-4c6a-b5ad-46b1b9798de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(train_images_paths,train_masks_paths)\n",
    "\n",
    "# construction d'un itérateur\n",
    "iterateur = iter(dataset)\n",
    "\n",
    "# récupération du premier jeu (image,masque) du dataset\n",
    "element_dataset = next(iterateur)\n",
    "image = element_dataset[\"image\"]\n",
    "masque = element_dataset[\"masque\"]\n",
    "\n",
    "print(image.shape)\n",
    "print(masque.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c893546-3235-419f-9b25-9313eac153d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, display_min=50, display_max=400, ax=None):\n",
    "    \"\"\"Show an image.\n",
    "    Args:\n",
    "        image (numpay.array[uint16]): the image. If the image is 16-bit, apply bytescaling to convert to 8-bit\n",
    "    \"\"\"\n",
    "    if image.dtype == np.uint16:\n",
    "        iscale = display_max - display_min\n",
    "        scale = 255 / iscale\n",
    "        byte_im = (image) * scale\n",
    "        byte_im = (byte_im.clip(0, 255) + 0.5).astype(np.uint8)\n",
    "        image = byte_im\n",
    "    # show image\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "def show_mask(mask, classes_colorpalette, classes=None, add_legend=True, ax=None):\n",
    "    \"\"\"Show a a semantic segmentation mask.\n",
    "    Args:\n",
    "       mask (numpy.array[uint8]): the mask in 8-bit\n",
    "       classes_colorpalette (dict[int, tuple]): dict mapping class index to an RGB color in [0, 1]\n",
    "       classes (list[str], optional): list of class labels\n",
    "       add_legend\n",
    "    \"\"\"\n",
    "    show_mask = np.empty((*mask.shape, 3))\n",
    "    for c, color in classes_colorpalette.items():\n",
    "        show_mask[mask == c, :] = color\n",
    "    show_mask = show_mask.astype(np.uint8)\n",
    "    \n",
    "    plt.imshow(show_mask)\n",
    "    handles = []\n",
    "    for c, color in LandCoverData.CLASSES_COLORPALETTE.items():        \n",
    "        handles.append(mpatches.Patch(color=color/255, label=LandCoverData.CLASSES[c]))\n",
    "    plt.legend(handles=handles)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8887deee-fcf3-4dec-8df2-bed04bfa0aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Image\")\n",
    "show_image(np.array(image).astype(np.uint16),display_min = 0, display_max = 2200)\n",
    "\n",
    "print(\"masque\")\n",
    "show_mask(np.array(masque),LandCoverData.CLASSES_COLORPALETTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a0c370-37bc-4c15-b1de-5d798284628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config ={\n",
    "    'monitoring' : True,\n",
    "    'freq monitoring':50,\n",
    "    'n_epoch' : 80,\n",
    "    'train_size' : 15000,\n",
    "    'batch_size' :  28,\n",
    "    'optimizer' : \"SGD\",\n",
    "    'lr' : 0.003,    \n",
    "    'momentum' : 0.9,\n",
    "    'model type': \"segmentation mask\",\n",
    "    'init_features'  : 16,\n",
    "    'validation_n_batch' : 2000,\n",
    "    'descriptif': \"Entrainement avec un unet pour segmentation + cross entropy\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23990acb-937d-471b-baae-e5a66583e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size =  config['batch_size']\n",
    "all_dataset = CustomDataset(train_images_paths,train_masks_paths)\n",
    "all_loader = DataLoader(all_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "train_size = config['train_size']\n",
    "val_size = len(all_dataset.mask_paths) - train_size\n",
    "#dans la liste donner la taille du train et la taille deu test\n",
    "train_dataset, valid_dataset = random_split(all_dataset,[train_size,val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                          shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5927fe-c65b-4926-beca-533ab673429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self, init_features,in_channels=4, out_channels=10):\n",
    "        super(Unet, self).__init__()\n",
    "        features = init_features\n",
    "        self.encoder1 = Unet._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = Unet._block(features, features * 4, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.bottleneck = Unet._block(features * 4, features * 8, name=\"bottleneck\")\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = Unet._block((features * 4) * 2, features * 4, name=\"dec2\")\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features * 4, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = Unet._block(features * 2, features, name=\"dec1\")\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        \n",
    "        bottleneck = self.bottleneck(self.pool2(enc2))\n",
    "\n",
    "        dec2 = self.upconv2(bottleneck)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        \n",
    "        return torch.sigmoid(self.conv(dec1))\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (name + \"conv1\", nn.Conv2d(in_channels=in_channels, out_channels=features, kernel_size=3, padding=1, bias=False,),),\n",
    "                    (name + \"Batchnorm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (name + \"conv2\",nn.Conv2d(in_channels=features, out_channels=features, kernel_size=3, padding=1, bias=False,),),\n",
    "                    (name + \"Batchnorm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b47e7a-96ff-4b50-becd-cbaccca99c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet_dl(nn.Module):\n",
    "    def __init__(self,init_features):\n",
    "        super().__init__()\n",
    "        self.unet = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "        in_channels= 4, out_channels=10, init_features= init_features, pretrained=False, verbose = False)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.unet(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23047c9-cb09-474c-9492-542a08ebff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f995b5-00c7-4602-889d-596292c4d9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Unet(config['init_features'])\n",
    "get_n_params(net) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4a15cc-9731-4146-80ab-2bc69ecce8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Unet(config['init_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e476c-c7a5-4445-acfb-7b2958ee07b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=config['lr'], momentum=config['momentum'])\n",
    "\n",
    "net = net.to(device)\n",
    "\n",
    "entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(config['n_epoch']): \n",
    "    \n",
    "       \n",
    "        net = net.to(device)    \n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        t= tqdm(train_loader, desc=\"epoch %i\" % (epoch+1),position = 0, leave=True)\n",
    "        epoch_loop = enumerate(t)\n",
    "\n",
    "        for i, data in epoch_loop:\n",
    "\n",
    "            taille_batch = data['image'].shape[0]\n",
    "            images = data['image'].permute(0,3,1,2)\n",
    "            masques  =  data['masque']\n",
    "\n",
    "            \n",
    "            images, masques = images.to(device), masques.long().to(device)\n",
    "\n",
    "            y_hat = net(images)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = entropy(y_hat,masques)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            del images, masques, y_hat # libéreer un peu d'espace\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if (i+1) % config['freq monitoring'] == 0:  \n",
    "                t.set_description(\"epoch %i, 'mean loss: %.6f'\" % (epoch+1,running_loss/config['freq monitoring']))\n",
    "                t.refresh()\n",
    "                running_loss =0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
